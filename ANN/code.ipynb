{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f39ae3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6932, Accuracy: 0.43\n",
      "Epoch 100, Loss: 0.6832, Accuracy: 0.57\n",
      "Epoch 200, Loss: 0.6829, Accuracy: 0.57\n",
      "Epoch 300, Loss: 0.6826, Accuracy: 0.57\n",
      "Epoch 400, Loss: 0.6822, Accuracy: 0.57\n",
      "Epoch 500, Loss: 0.6815, Accuracy: 0.57\n",
      "Epoch 600, Loss: 0.6804, Accuracy: 0.57\n",
      "Epoch 700, Loss: 0.6787, Accuracy: 0.57\n",
      "Epoch 800, Loss: 0.6760, Accuracy: 0.57\n",
      "Epoch 900, Loss: 0.6716, Accuracy: 0.57\n",
      "Final Accuracy: 0.57\n"
     ]
    }
   ],
   "source": [
    "#Feedforward ANN from Scratch (Python + NumPy)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 1. Create a small custom dataset (binary classification)\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 2)  # 100 samples, 2 features\n",
    "y = (X[:, 0] + X[:, 1] > 1).astype(int).reshape(-1, 1)  # label=1 if sum > 1 else 0\n",
    "\n",
    "# 2. Helper functions\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def sigmoid_deriv(z):\n",
    "    s = sigmoid(z)\n",
    "    return s * (1 - s)\n",
    "\n",
    "def binary_cross_entropy(y_true, y_pred):\n",
    "    eps = 1e-8  # to avoid log(0)\n",
    "    return -np.mean(y_true*np.log(y_pred+eps) + (1-y_true)*np.log(1-y_pred+eps))\n",
    "\n",
    "# 3. Initialize weights\n",
    "input_dim = 2\n",
    "hidden_dim = 4\n",
    "output_dim = 1\n",
    "\n",
    "W1 = np.random.randn(input_dim, hidden_dim) * 0.01\n",
    "b1 = np.zeros((1, hidden_dim))\n",
    "W2 = np.random.randn(hidden_dim, output_dim) * 0.01\n",
    "b2 = np.zeros((1, output_dim))\n",
    "\n",
    "# 4. Training\n",
    "lr = 0.1\n",
    "epochs = 1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # ---- Forward ----\n",
    "    z1 = X @ W1 + b1\n",
    "    a1 = sigmoid(z1)\n",
    "\n",
    "    z2 = a1 @ W2 + b2\n",
    "    a2 = sigmoid(z2)  # prediction\n",
    "\n",
    "    # ---- Loss ----\n",
    "    loss = binary_cross_entropy(y, a2)\n",
    "\n",
    "    # ---- Backprop ----\n",
    "    dz2 = a2 - y\n",
    "    dW2 = a1.T @ dz2 / X.shape[0]\n",
    "    db2 = np.mean(dz2, axis=0, keepdims=True)\n",
    "\n",
    "    dz1 = (dz2 @ W2.T) * sigmoid_deriv(z1)\n",
    "    dW1 = X.T @ dz1 / X.shape[0]\n",
    "    db1 = np.mean(dz1, axis=0, keepdims=True)\n",
    "\n",
    "    # ---- Update ----\n",
    "    W1 -= lr * dW1\n",
    "    b1 -= lr * db1\n",
    "    W2 -= lr * dW2\n",
    "    b2 -= lr * db2\n",
    "\n",
    "    # Print every 100 epochs\n",
    "    if epoch % 100 == 0:\n",
    "        preds = (a2 > 0.5).astype(int)\n",
    "        acc = np.mean(preds == y)\n",
    "        print(f\"Epoch {epoch}, Loss: {loss:.4f}, Accuracy: {acc:.2f}\")\n",
    "\n",
    "# Final evaluation\n",
    "preds = (a2 > 0.5).astype(int)\n",
    "print(\"Final Accuracy:\", np.mean(preds == y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "998abdeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.7204, Accuracy: 0.43\n",
      "Epoch 100, Loss: 0.0614, Accuracy: 0.98\n",
      "Epoch 200, Loss: 0.0392, Accuracy: 0.99\n",
      "Epoch 300, Loss: 0.0302, Accuracy: 0.99\n",
      "Epoch 400, Loss: 0.0252, Accuracy: 0.99\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Dataset\n",
    "X_t = torch.tensor(X, dtype=torch.float32)\n",
    "y_t = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "# 2. Model\n",
    "class SimpleANN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleANN, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 4)\n",
    "        self.fc2 = nn.Linear(4, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "model = SimpleANN()\n",
    "\n",
    "# 3. Loss & optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "# 4. Training loop\n",
    "losses = []\n",
    "for epoch in range(500):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_t)\n",
    "    loss = criterion(outputs, y_t)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(loss.item())\n",
    "    if epoch % 100 == 0:\n",
    "        with torch.no_grad():\n",
    "            preds = (outputs > 0.5).float()\n",
    "            acc = (preds == y_t).float().mean()\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item():.4f}, Accuracy: {acc:.2f}\")\n",
    "\n",
    "# 5. Save model\n",
    "torch.save(model.state_dict(), \"simple_ann.pth\")\n",
    "\n",
    "# 6. Load model\n",
    "loaded_model = SimpleANN()\n",
    "loaded_model.load_state_dict(torch.load(\"simple_ann.pth\"))\n",
    "loaded_model.eval()\n",
    "\n",
    "# 7. Plot training loss\n",
    "plt.plot(losses)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9cf6afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 0.6538 Acc: 0.5625 | Val Loss: 0.6457 Acc: 0.4750\n",
      " --> New best model saved (val_loss: 0.6457)\n",
      "Epoch 002 | Train Loss: 0.6190 Acc: 0.5387 | Val Loss: 0.6241 Acc: 0.5000\n",
      " --> New best model saved (val_loss: 0.6241)\n",
      "Epoch 003 | Train Loss: 0.5966 Acc: 0.5737 | Val Loss: 0.5992 Acc: 0.5450\n",
      " --> New best model saved (val_loss: 0.5992)\n",
      "Epoch 004 | Train Loss: 0.5743 Acc: 0.6200 | Val Loss: 0.5816 Acc: 0.5700\n",
      " --> New best model saved (val_loss: 0.5816)\n",
      "Epoch 005 | Train Loss: 0.5531 Acc: 0.6500 | Val Loss: 0.5595 Acc: 0.6300\n",
      " --> New best model saved (val_loss: 0.5595)\n",
      "Epoch 006 | Train Loss: 0.5317 Acc: 0.7250 | Val Loss: 0.5371 Acc: 0.7100\n",
      " --> New best model saved (val_loss: 0.5371)\n",
      "Epoch 007 | Train Loss: 0.5100 Acc: 0.7913 | Val Loss: 0.5148 Acc: 0.7400\n",
      " --> New best model saved (val_loss: 0.5148)\n",
      "Epoch 008 | Train Loss: 0.4867 Acc: 0.8037 | Val Loss: 0.4943 Acc: 0.7600\n",
      " --> New best model saved (val_loss: 0.4943)\n",
      "Epoch 009 | Train Loss: 0.4636 Acc: 0.8187 | Val Loss: 0.4671 Acc: 0.7850\n",
      " --> New best model saved (val_loss: 0.4671)\n",
      "Epoch 010 | Train Loss: 0.4413 Acc: 0.8475 | Val Loss: 0.4402 Acc: 0.8100\n",
      " --> New best model saved (val_loss: 0.4402)\n",
      "Epoch 011 | Train Loss: 0.4188 Acc: 0.8538 | Val Loss: 0.4181 Acc: 0.8250\n",
      " --> New best model saved (val_loss: 0.4181)\n",
      "Epoch 012 | Train Loss: 0.3953 Acc: 0.8562 | Val Loss: 0.3952 Acc: 0.8500\n",
      " --> New best model saved (val_loss: 0.3952)\n",
      "Epoch 013 | Train Loss: 0.3740 Acc: 0.8650 | Val Loss: 0.3707 Acc: 0.8700\n",
      " --> New best model saved (val_loss: 0.3707)\n",
      "Epoch 014 | Train Loss: 0.3540 Acc: 0.8675 | Val Loss: 0.3512 Acc: 0.8700\n",
      " --> New best model saved (val_loss: 0.3512)\n",
      "Epoch 015 | Train Loss: 0.3332 Acc: 0.8775 | Val Loss: 0.3238 Acc: 0.8900\n",
      " --> New best model saved (val_loss: 0.3238)\n",
      "Epoch 016 | Train Loss: 0.3143 Acc: 0.8925 | Val Loss: 0.3073 Acc: 0.8850\n",
      " --> New best model saved (val_loss: 0.3073)\n",
      "Epoch 017 | Train Loss: 0.2975 Acc: 0.8900 | Val Loss: 0.2920 Acc: 0.8950\n",
      " --> New best model saved (val_loss: 0.2920)\n",
      "Epoch 018 | Train Loss: 0.2813 Acc: 0.8925 | Val Loss: 0.2739 Acc: 0.9000\n",
      " --> New best model saved (val_loss: 0.2739)\n",
      "Epoch 019 | Train Loss: 0.2663 Acc: 0.9075 | Val Loss: 0.2552 Acc: 0.9150\n",
      " --> New best model saved (val_loss: 0.2552)\n",
      "Epoch 020 | Train Loss: 0.2528 Acc: 0.9137 | Val Loss: 0.2413 Acc: 0.9200\n",
      " --> New best model saved (val_loss: 0.2413)\n",
      "Epoch 021 | Train Loss: 0.2394 Acc: 0.9250 | Val Loss: 0.2308 Acc: 0.9250\n",
      " --> New best model saved (val_loss: 0.2308)\n",
      "Epoch 022 | Train Loss: 0.2271 Acc: 0.9275 | Val Loss: 0.2153 Acc: 0.9300\n",
      " --> New best model saved (val_loss: 0.2153)\n",
      "Epoch 023 | Train Loss: 0.2173 Acc: 0.9250 | Val Loss: 0.2080 Acc: 0.9300\n",
      " --> New best model saved (val_loss: 0.2080)\n",
      "Epoch 024 | Train Loss: 0.2067 Acc: 0.9400 | Val Loss: 0.1933 Acc: 0.9300\n",
      " --> New best model saved (val_loss: 0.1933)\n",
      "Epoch 025 | Train Loss: 0.1954 Acc: 0.9363 | Val Loss: 0.1899 Acc: 0.9350\n",
      " --> New best model saved (val_loss: 0.1899)\n",
      "Epoch 026 | Train Loss: 0.1875 Acc: 0.9363 | Val Loss: 0.1798 Acc: 0.9400\n",
      " --> New best model saved (val_loss: 0.1798)\n",
      "Epoch 027 | Train Loss: 0.1780 Acc: 0.9425 | Val Loss: 0.1705 Acc: 0.9350\n",
      " --> New best model saved (val_loss: 0.1705)\n",
      "Epoch 028 | Train Loss: 0.1697 Acc: 0.9463 | Val Loss: 0.1600 Acc: 0.9350\n",
      " --> New best model saved (val_loss: 0.1600)\n",
      "Epoch 029 | Train Loss: 0.1635 Acc: 0.9425 | Val Loss: 0.1528 Acc: 0.9350\n",
      " --> New best model saved (val_loss: 0.1528)\n",
      "Epoch 030 | Train Loss: 0.1562 Acc: 0.9500 | Val Loss: 0.1468 Acc: 0.9400\n",
      " --> New best model saved (val_loss: 0.1468)\n",
      "Epoch 031 | Train Loss: 0.1500 Acc: 0.9500 | Val Loss: 0.1442 Acc: 0.9400\n",
      " --> New best model saved (val_loss: 0.1442)\n",
      "Epoch 032 | Train Loss: 0.1441 Acc: 0.9525 | Val Loss: 0.1371 Acc: 0.9500\n",
      " --> New best model saved (val_loss: 0.1371)\n",
      "Epoch 033 | Train Loss: 0.1395 Acc: 0.9575 | Val Loss: 0.1323 Acc: 0.9450\n",
      " --> New best model saved (val_loss: 0.1323)\n",
      "Epoch 034 | Train Loss: 0.1338 Acc: 0.9613 | Val Loss: 0.1285 Acc: 0.9450\n",
      " --> New best model saved (val_loss: 0.1285)\n",
      "Epoch 035 | Train Loss: 0.1292 Acc: 0.9625 | Val Loss: 0.1242 Acc: 0.9550\n",
      " --> New best model saved (val_loss: 0.1242)\n",
      "Epoch 036 | Train Loss: 0.1256 Acc: 0.9587 | Val Loss: 0.1168 Acc: 0.9700\n",
      " --> New best model saved (val_loss: 0.1168)\n",
      "Epoch 037 | Train Loss: 0.1216 Acc: 0.9637 | Val Loss: 0.1172 Acc: 0.9600\n",
      "Epoch 038 | Train Loss: 0.1173 Acc: 0.9688 | Val Loss: 0.1105 Acc: 0.9750\n",
      " --> New best model saved (val_loss: 0.1105)\n",
      "Epoch 039 | Train Loss: 0.1155 Acc: 0.9750 | Val Loss: 0.1115 Acc: 0.9650\n",
      "Epoch 040 | Train Loss: 0.1104 Acc: 0.9788 | Val Loss: 0.1049 Acc: 0.9800\n",
      " --> New best model saved (val_loss: 0.1049)\n",
      "Epoch 041 | Train Loss: 0.1093 Acc: 0.9700 | Val Loss: 0.1093 Acc: 0.9550\n",
      "Epoch 042 | Train Loss: 0.1050 Acc: 0.9800 | Val Loss: 0.0999 Acc: 0.9850\n",
      " --> New best model saved (val_loss: 0.0999)\n",
      "Epoch 043 | Train Loss: 0.1027 Acc: 0.9800 | Val Loss: 0.0982 Acc: 0.9800\n",
      " --> New best model saved (val_loss: 0.0982)\n",
      "Epoch 044 | Train Loss: 0.0997 Acc: 0.9800 | Val Loss: 0.0967 Acc: 0.9850\n",
      " --> New best model saved (val_loss: 0.0967)\n",
      "Epoch 045 | Train Loss: 0.0969 Acc: 0.9850 | Val Loss: 0.0923 Acc: 0.9850\n",
      " --> New best model saved (val_loss: 0.0923)\n",
      "Epoch 046 | Train Loss: 0.0943 Acc: 0.9838 | Val Loss: 0.0924 Acc: 0.9850\n",
      "Epoch 047 | Train Loss: 0.0921 Acc: 0.9825 | Val Loss: 0.0905 Acc: 0.9850\n",
      " --> New best model saved (val_loss: 0.0905)\n",
      "Epoch 048 | Train Loss: 0.0908 Acc: 0.9850 | Val Loss: 0.0871 Acc: 0.9850\n",
      " --> New best model saved (val_loss: 0.0871)\n",
      "Epoch 049 | Train Loss: 0.0889 Acc: 0.9838 | Val Loss: 0.0893 Acc: 0.9850\n",
      "Epoch 050 | Train Loss: 0.0864 Acc: 0.9875 | Val Loss: 0.0845 Acc: 0.9900\n",
      " --> New best model saved (val_loss: 0.0845)\n",
      "Epoch 051 | Train Loss: 0.0854 Acc: 0.9862 | Val Loss: 0.0831 Acc: 0.9900\n",
      " --> New best model saved (val_loss: 0.0831)\n",
      "Epoch 052 | Train Loss: 0.0845 Acc: 0.9838 | Val Loss: 0.0846 Acc: 0.9850\n",
      "Epoch 053 | Train Loss: 0.0827 Acc: 0.9850 | Val Loss: 0.0781 Acc: 0.9850\n",
      " --> New best model saved (val_loss: 0.0781)\n",
      "Epoch 054 | Train Loss: 0.0809 Acc: 0.9888 | Val Loss: 0.0820 Acc: 0.9850\n",
      "Epoch 055 | Train Loss: 0.0798 Acc: 0.9888 | Val Loss: 0.0761 Acc: 0.9900\n",
      " --> New best model saved (val_loss: 0.0761)\n",
      "Epoch 056 | Train Loss: 0.0810 Acc: 0.9850 | Val Loss: 0.0810 Acc: 0.9900\n",
      "Epoch 057 | Train Loss: 0.0789 Acc: 0.9838 | Val Loss: 0.0740 Acc: 0.9950\n",
      " --> New best model saved (val_loss: 0.0740)\n",
      "Epoch 058 | Train Loss: 0.0755 Acc: 0.9875 | Val Loss: 0.0740 Acc: 0.9900\n",
      " --> New best model saved (val_loss: 0.0740)\n",
      "Epoch 059 | Train Loss: 0.0744 Acc: 0.9888 | Val Loss: 0.0760 Acc: 0.9900\n",
      "Epoch 060 | Train Loss: 0.0728 Acc: 0.9912 | Val Loss: 0.0710 Acc: 0.9950\n",
      " --> New best model saved (val_loss: 0.0710)\n",
      "Epoch 061 | Train Loss: 0.0717 Acc: 0.9888 | Val Loss: 0.0712 Acc: 0.9950\n",
      "Epoch 062 | Train Loss: 0.0714 Acc: 0.9925 | Val Loss: 0.0685 Acc: 0.9950\n",
      " --> New best model saved (val_loss: 0.0685)\n",
      "Epoch 063 | Train Loss: 0.0707 Acc: 0.9912 | Val Loss: 0.0713 Acc: 0.9900\n",
      "Epoch 064 | Train Loss: 0.0690 Acc: 0.9912 | Val Loss: 0.0673 Acc: 0.9950\n",
      " --> New best model saved (val_loss: 0.0673)\n",
      "Epoch 065 | Train Loss: 0.0688 Acc: 0.9875 | Val Loss: 0.0655 Acc: 0.9900\n",
      " --> New best model saved (val_loss: 0.0655)\n",
      "Epoch 066 | Train Loss: 0.0675 Acc: 0.9900 | Val Loss: 0.0664 Acc: 0.9950\n",
      "Epoch 067 | Train Loss: 0.0661 Acc: 0.9888 | Val Loss: 0.0672 Acc: 0.9900\n",
      "Epoch 068 | Train Loss: 0.0654 Acc: 0.9912 | Val Loss: 0.0670 Acc: 0.9950\n",
      "Epoch 069 | Train Loss: 0.0642 Acc: 0.9912 | Val Loss: 0.0644 Acc: 0.9950\n",
      " --> New best model saved (val_loss: 0.0644)\n",
      "Epoch 070 | Train Loss: 0.0643 Acc: 0.9938 | Val Loss: 0.0650 Acc: 0.9950\n",
      "Epoch 071 | Train Loss: 0.0639 Acc: 0.9900 | Val Loss: 0.0626 Acc: 0.9950\n",
      " --> New best model saved (val_loss: 0.0626)\n",
      "Epoch 072 | Train Loss: 0.0615 Acc: 0.9938 | Val Loss: 0.0644 Acc: 0.9950\n",
      "Epoch 073 | Train Loss: 0.0626 Acc: 0.9888 | Val Loss: 0.0600 Acc: 0.9900\n",
      " --> New best model saved (val_loss: 0.0600)\n",
      "Epoch 074 | Train Loss: 0.0604 Acc: 0.9912 | Val Loss: 0.0613 Acc: 0.9950\n",
      "Epoch 075 | Train Loss: 0.0601 Acc: 0.9925 | Val Loss: 0.0593 Acc: 0.9950\n",
      " --> New best model saved (val_loss: 0.0593)\n",
      "Epoch 076 | Train Loss: 0.0593 Acc: 0.9925 | Val Loss: 0.0584 Acc: 0.9950\n",
      " --> New best model saved (val_loss: 0.0584)\n",
      "Epoch 077 | Train Loss: 0.0583 Acc: 0.9925 | Val Loss: 0.0596 Acc: 0.9950\n",
      "Epoch 078 | Train Loss: 0.0589 Acc: 0.9875 | Val Loss: 0.0613 Acc: 0.9900\n",
      "Epoch 079 | Train Loss: 0.0593 Acc: 0.9900 | Val Loss: 0.0577 Acc: 0.9900\n",
      " --> New best model saved (val_loss: 0.0577)\n",
      "Epoch 080 | Train Loss: 0.0590 Acc: 0.9862 | Val Loss: 0.0596 Acc: 0.9900\n",
      "Epoch 081 | Train Loss: 0.0563 Acc: 0.9950 | Val Loss: 0.0562 Acc: 0.9950\n",
      " --> New best model saved (val_loss: 0.0562)\n",
      "Epoch 082 | Train Loss: 0.0573 Acc: 0.9888 | Val Loss: 0.0590 Acc: 0.9900\n",
      "Epoch 083 | Train Loss: 0.0562 Acc: 0.9900 | Val Loss: 0.0537 Acc: 0.9900\n",
      " --> New best model saved (val_loss: 0.0537)\n",
      "Epoch 084 | Train Loss: 0.0554 Acc: 0.9925 | Val Loss: 0.0567 Acc: 0.9950\n",
      "Epoch 085 | Train Loss: 0.0540 Acc: 0.9925 | Val Loss: 0.0560 Acc: 0.9950\n",
      "Epoch 086 | Train Loss: 0.0543 Acc: 0.9912 | Val Loss: 0.0529 Acc: 0.9950\n",
      " --> New best model saved (val_loss: 0.0529)\n",
      "Epoch 087 | Train Loss: 0.0552 Acc: 0.9900 | Val Loss: 0.0526 Acc: 0.9950\n",
      " --> New best model saved (val_loss: 0.0526)\n",
      "Epoch 088 | Train Loss: 0.0536 Acc: 0.9875 | Val Loss: 0.0541 Acc: 0.9950\n",
      "Epoch 089 | Train Loss: 0.0524 Acc: 0.9938 | Val Loss: 0.0519 Acc: 0.9950\n",
      " --> New best model saved (val_loss: 0.0519)\n",
      "Epoch 090 | Train Loss: 0.0507 Acc: 0.9938 | Val Loss: 0.0530 Acc: 0.9950\n",
      "Epoch 091 | Train Loss: 0.0507 Acc: 0.9938 | Val Loss: 0.0524 Acc: 0.9950\n",
      "Epoch 092 | Train Loss: 0.0500 Acc: 0.9962 | Val Loss: 0.0507 Acc: 0.9950\n",
      " --> New best model saved (val_loss: 0.0507)\n",
      "Epoch 093 | Train Loss: 0.0500 Acc: 0.9900 | Val Loss: 0.0512 Acc: 0.9950\n",
      "Epoch 094 | Train Loss: 0.0491 Acc: 0.9925 | Val Loss: 0.0503 Acc: 0.9950\n",
      " --> New best model saved (val_loss: 0.0503)\n",
      "Epoch 095 | Train Loss: 0.0503 Acc: 0.9900 | Val Loss: 0.0498 Acc: 0.9950\n",
      " --> New best model saved (val_loss: 0.0498)\n",
      "Epoch 096 | Train Loss: 0.0534 Acc: 0.9850 | Val Loss: 0.0493 Acc: 0.9900\n",
      " --> New best model saved (val_loss: 0.0493)\n",
      "Epoch 097 | Train Loss: 0.0486 Acc: 0.9888 | Val Loss: 0.0513 Acc: 0.9950\n",
      "Epoch 098 | Train Loss: 0.0483 Acc: 0.9938 | Val Loss: 0.0468 Acc: 0.9950\n",
      " --> New best model saved (val_loss: 0.0468)\n",
      "Epoch 099 | Train Loss: 0.0480 Acc: 0.9888 | Val Loss: 0.0493 Acc: 0.9950\n",
      "Epoch 100 | Train Loss: 0.0473 Acc: 0.9912 | Val Loss: 0.0482 Acc: 0.9950\n",
      "\n",
      "Final best-model evaluation -> Train Acc: 0.9912 RMSE: 0.1070 | Val Acc: 0.9950 RMSE: 0.1053\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1) Create simple dataset (binary classification)\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(1000, 2).astype(np.float32)  # 1000 samples, 2 features, float32 for PyTorch\n",
    "y = ((X[:, 0] + X[:, 1]) > 1).astype(np.float32).reshape(-1, 1)  # Label=1 if sum of features > 1 else 0\n",
    "\n",
    "# Split dataset into training and validation sets (80% train, 20% val)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "X_train_t = torch.from_numpy(X_train)\n",
    "y_train_t = torch.from_numpy(y_train)\n",
    "X_val_t = torch.from_numpy(X_val)\n",
    "y_val_t = torch.from_numpy(y_val)\n",
    "\n",
    "# Create Dataset and DataLoader objects for batching\n",
    "batch_size = 64\n",
    "train_ds = TensorDataset(X_train_t, y_train_t)  # Dataset for training\n",
    "val_ds = TensorDataset(X_val_t, y_val_t)        # Dataset for validation\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)  # Shuffle training data\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)     # No shuffle for validation\n",
    "\n",
    "# 2) Define the model architecture\n",
    "class SimpleANN(nn.Module):\n",
    "    def __init__(self, hidden_dim=16, use_batchnorm=False):\n",
    "        super(SimpleANN, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, hidden_dim)  # First fully connected layer (input to hidden)\n",
    "        # BatchNorm can be enabled here if needed:\n",
    "        # self.bn1 = nn.BatchNorm1d(hidden_dim) if use_batchnorm else None\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)  # Second hidden layer\n",
    "        # self.bn2 = nn.BatchNorm1d(hidden_dim) if use_batchnorm else None\n",
    "        self.fc3 = nn.Linear(hidden_dim, 1)  # Output layer (1 output for binary classification)\n",
    "        self.act = nn.ReLU()  # ReLU activation for hidden layers\n",
    "        self.out_act = nn.Sigmoid()  # Sigmoid activation for output (probability)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)  # Linear transform\n",
    "        # if self.bn1 is not None: x = self.bn1(x)  # Optional BatchNorm\n",
    "        x = self.act(x)  # Apply ReLU\n",
    "        x = self.fc2(x)  # Linear transform second hidden layer\n",
    "        # if self.bn2 is not None: x = self.bn2(x)  # Optional BatchNorm\n",
    "        x = self.act(x)  # Apply ReLU\n",
    "        x = self.fc3(x)  # Final linear transform to output\n",
    "        x = self.out_act(x)  # Sigmoid to get probability\n",
    "        return x\n",
    "\n",
    "# Detect if CUDA GPU is available, else use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleANN(hidden_dim=32).to(device)  # Create model and send to device (GPU or CPU)\n",
    "\n",
    "# 3) Initialize weights using He initialization (good for ReLU activations)\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')  # He init for weights\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)  # Initialize biases to zero\n",
    "\n",
    "model.apply(init_weights)  # Apply initialization function to all layers\n",
    "\n",
    "# 4) Define loss function, optimizer, scheduler, and weight decay (L2 regularization)\n",
    "criterion = nn.BCELoss()  # Binary cross entropy loss (for binary classification)\n",
    "lr = 1e-3  # Learning rate\n",
    "weight_decay = 1e-4  # L2 penalty (weight decay) to reduce overfitting\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=5\n",
    ")  # Reduce LR when val loss plateaus (no verbose arg for compatibility)\n",
    "\n",
    "# 5) Training loop with early stopping\n",
    "num_epochs = 100  # Max number of epochs to train\n",
    "patience = 12  # Number of epochs with no improvement before stopping early\n",
    "best_val_loss = float('inf')  # Track best validation loss\n",
    "epochs_no_improve = 0  # Counter for early stopping\n",
    "history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}  # Store loss and acc per epoch\n",
    "save_path = \"best_simple_ann.pth\"  # File path to save best model\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    # ---- Training phase ----\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0  # Sum of losses over batches\n",
    "    running_corrects = 0  # Number of correct predictions\n",
    "    total = 0  # Total samples processed\n",
    "\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)  # Move batch to device\n",
    "\n",
    "        optimizer.zero_grad()  # Clear previous gradients\n",
    "        preds = model(xb)  # Forward pass\n",
    "        loss = criterion(preds, yb)  # Compute loss\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update weights\n",
    "\n",
    "        running_loss += loss.item() * xb.size(0)  # Accumulate loss scaled by batch size\n",
    "        preds_label = (preds.detach() > 0.5).float()  # Convert probabilities to binary predictions\n",
    "        running_corrects += (preds_label == yb).sum().item()  # Count correct predictions\n",
    "        total += xb.size(0)  # Count samples\n",
    "\n",
    "    train_loss = running_loss / total  # Average loss over epoch\n",
    "    train_acc = running_corrects / total  # Accuracy over epoch\n",
    "\n",
    "    # ---- Validation phase ----\n",
    "    model.eval()  # Set model to evaluation mode (disables dropout, batchnorm updates)\n",
    "    val_running_loss = 0.0\n",
    "    val_running_corrects = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():  # No gradients needed for validation\n",
    "        for xb, yb in val_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            preds = model(xb)\n",
    "            loss = criterion(preds, yb)\n",
    "            val_running_loss += loss.item() * xb.size(0)\n",
    "            preds_label = (preds > 0.5).float()\n",
    "            val_running_corrects += (preds_label == yb).sum().item()\n",
    "            val_total += xb.size(0)\n",
    "\n",
    "    val_loss = val_running_loss / val_total\n",
    "    val_acc = val_running_corrects / val_total\n",
    "\n",
    "    # Save loss and accuracy for plotting later\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_acc'].append(val_acc)\n",
    "\n",
    "    # Step the LR scheduler and print if LR changed\n",
    "    old_lr = optimizer.param_groups[0]['lr']  # Current LR before scheduler step\n",
    "    scheduler.step(val_loss)  # Update LR based on val loss plateau\n",
    "    new_lr = optimizer.param_groups[0]['lr']  # LR after scheduler step\n",
    "    if new_lr != old_lr:\n",
    "        print(f\"Learning rate reduced to {new_lr:.6f}\")\n",
    "\n",
    "    # Print epoch summary\n",
    "    print(f\"Epoch {epoch:03d} | Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # Early stopping check: if validation loss improved, save model and reset counter\n",
    "    if val_loss < best_val_loss - 1e-6:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss\n",
    "        }, save_path)\n",
    "        print(f\" --> New best model saved (val_loss: {val_loss:.4f})\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        # Stop training if no improvement for 'patience' epochs\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch} epochs.\")\n",
    "            break\n",
    "\n",
    "# 6) Load the best saved model for final evaluation\n",
    "ckpt = torch.load(save_path, map_location=device)\n",
    "model.load_state_dict(ckpt['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# Evaluation function to calculate accuracy and RMSE on given DataLoader\n",
    "def evaluate(loader):\n",
    "    preds_all = []\n",
    "    targets_all = []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            preds = model(xb)\n",
    "            preds_all.append(preds.cpu().numpy())\n",
    "            targets_all.append(yb.cpu().numpy())\n",
    "    preds_all = np.vstack(preds_all)\n",
    "    targets_all = np.vstack(targets_all)\n",
    "    preds_label = (preds_all > 0.5).astype(np.float32)  # Binary predictions\n",
    "    acc = (preds_label == targets_all).mean()  # Accuracy\n",
    "    rmse = np.sqrt(((preds_all - targets_all) ** 2).mean())  # Root mean squared error\n",
    "    return acc, rmse\n",
    "\n",
    "# Evaluate on training and validation sets\n",
    "train_acc, train_rmse = evaluate(train_loader)\n",
    "val_acc, val_rmse = evaluate(val_loader)\n",
    "\n",
    "print(f\"\\nFinal best-model evaluation -> Train Acc: {train_acc:.4f} RMSE: {train_rmse:.4f} | Val Acc: {val_acc:.4f} RMSE: {val_rmse:.4f}\")\n",
    "\n",
    "# 7) Plot training and validation loss curves for visualization\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(history['train_loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training & Validation Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8330c8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0100,  0.0000,  1.0000])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "leaky_relu = nn.LeakyReLU(negative_slope=0.01)\n",
    "x = torch.tensor([-1.0, 0.0, 1.0])\n",
    "print(leaky_relu(x))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52524973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0900, 0.2447, 0.6652]])\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "logits = torch.tensor([[1.0, 2.0, 3.0]])\n",
    "probs = softmax(logits)\n",
    "print(probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "427cd292",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d6f7568",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "742288e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = nn.Dropout(p=0.5)\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(10, 20),\n",
    "    nn.ReLU(),\n",
    "    dropout,\n",
    "    nn.Linear(20, 1)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9068ba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn = nn.BatchNorm1d(num_features=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6679c3ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=10, out_features=20, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Dropout(p=0.5, inplace=False)\n",
       "  (3): Linear(in_features=20, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def xavier_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        nn.init.zeros_(m.bias)\n",
    "\n",
    "model.apply(xavier_init)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40905157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=10, out_features=20, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Dropout(p=0.5, inplace=False)\n",
       "  (3): Linear(in_features=20, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def he_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
    "        nn.init.zeros_(m.bias)\n",
    "\n",
    "model.apply(he_init)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfbcdea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.713693618774414\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "logits = torch.randn(3, 5)\n",
    "targets = torch.tensor([1, 0, 4])\n",
    "loss = criterion(logits, targets)\n",
    "print(loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83cd87b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17000000178813934\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "outputs = torch.tensor([2.5, 0.0, 2.1])\n",
    "targets = torch.tensor([3.0, -0.5, 2.0])\n",
    "loss = criterion(outputs, targets)\n",
    "print(loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b56bc3c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1b1b736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_grad_check(model, loss_fn, x, y, param_name, epsilon=1e-5):\n",
    "    model.eval()\n",
    "    param = dict(model.named_parameters())[param_name]\n",
    "    param_data = param.data.clone()\n",
    "    grad_approx = torch.zeros_like(param_data)\n",
    "    for idx in range(param_data.numel()):\n",
    "        orig = param_data.view(-1)[idx].item()\n",
    "        param_data.view(-1)[idx] = orig + epsilon\n",
    "        param.data = param_data\n",
    "        loss_plus = loss_fn(model(x), y).item()\n",
    "        param_data.view(-1)[idx] = orig - epsilon\n",
    "        param.data = param_data\n",
    "        loss_minus = loss_fn(model(x), y).item()\n",
    "        grad_approx.view(-1)[idx] = (loss_plus - loss_minus) / (2 * epsilon)\n",
    "        param_data.view(-1)[idx] = orig\n",
    "    param.data = param_data\n",
    "    return grad_approx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d6ccf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(784, 128), nn.ReLU(),\n",
    "            nn.Linear(128, 64), nn.ReLU(),\n",
    "            nn.Linear(64, 12), nn.ReLU(),\n",
    "            nn.Linear(12, 3)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3, 12), nn.ReLU(),\n",
    "            nn.Linear(12, 64), nn.ReLU(),\n",
    "            nn.Linear(64, 128), nn.ReLU(),\n",
    "            nn.Linear(128, 784), nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b788e0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.7060\n",
      "Epoch 2 Loss: 0.6486\n",
      "Epoch 3 Loss: 0.5944\n",
      "Epoch 4 Loss: 0.5413\n",
      "Epoch 5 Loss: 0.4985\n",
      "Epoch 6 Loss: 0.4596\n",
      "Epoch 7 Loss: 0.4171\n",
      "Epoch 8 Loss: 0.3814\n",
      "Epoch 9 Loss: 0.3511\n",
      "Epoch 10 Loss: 0.3152\n",
      "Epoch 11 Loss: 0.2896\n",
      "Epoch 12 Loss: 0.2711\n",
      "Epoch 13 Loss: 0.2529\n",
      "Epoch 14 Loss: 0.2424\n",
      "Epoch 15 Loss: 0.2317\n",
      "Epoch 16 Loss: 0.2099\n",
      "Epoch 17 Loss: 0.2130\n",
      "Epoch 18 Loss: 0.2147\n",
      "Epoch 19 Loss: 0.1806\n",
      "Epoch 20 Loss: 0.1750\n"
     ]
    }
   ],
   "source": [
    "# Training with Dropout & BatchNorm Example\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "# Dummy data\n",
    "X = np.random.rand(1000, 10).astype(np.float32)\n",
    "y = (X.sum(axis=1) > 5).astype(np.float32).reshape(-1, 1)\n",
    "\n",
    "X_t = torch.from_numpy(X)\n",
    "y_t = torch.from_numpy(y)\n",
    "\n",
    "dataset = TensorDataset(X_t, y_t)\n",
    "loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Model with Dropout and BatchNorm\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(10, 50)\n",
    "        self.bn1 = nn.BatchNorm1d(50)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(50, 1)\n",
    "        self.act = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return self.act(x)\n",
    "\n",
    "model = Model()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for xb, yb in loader:\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(xb)\n",
    "        loss = criterion(preds, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "    print(f\"Epoch {epoch+1} Loss: {total_loss/len(dataset):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729dde49",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e321b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.6904\n",
      "Epoch 2 Loss: 0.6801\n",
      "Epoch 3 Loss: 0.6686\n",
      "Epoch 4 Loss: 0.6569\n",
      "Epoch 5 Loss: 0.6461\n",
      "Epoch 6 Loss: 0.6333\n",
      "Epoch 7 Loss: 0.6213\n",
      "Epoch 8 Loss: 0.6087\n",
      "Epoch 9 Loss: 0.5959\n",
      "Epoch 10 Loss: 0.5833\n",
      "Epoch 11 Loss: 0.5694\n",
      "Epoch 12 Loss: 0.5551\n",
      "Epoch 13 Loss: 0.5400\n",
      "Epoch 14 Loss: 0.5253\n",
      "Epoch 15 Loss: 0.5091\n",
      "Epoch 16 Loss: 0.4936\n",
      "Epoch 17 Loss: 0.4772\n",
      "Epoch 18 Loss: 0.4614\n",
      "Epoch 19 Loss: 0.4453\n",
      "Epoch 20 Loss: 0.4294\n",
      "Epoch 21 Loss: 0.4143\n",
      "Epoch 22 Loss: 0.3984\n",
      "Epoch 23 Loss: 0.3838\n",
      "Epoch 24 Loss: 0.3706\n",
      "Epoch 25 Loss: 0.3569\n",
      "Epoch 26 Loss: 0.3444\n",
      "Epoch 27 Loss: 0.3324\n",
      "Epoch 28 Loss: 0.3213\n",
      "Epoch 29 Loss: 0.3105\n",
      "Epoch 30 Loss: 0.3053\n"
     ]
    }
   ],
   "source": [
    "# Training with Xavier Initialization & SGD + Momentum\n",
    "\n",
    "import torch.nn.init as init\n",
    "\n",
    "def xavier_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        init.xavier_uniform_(m.weight)\n",
    "        init.zeros_(m.bias)\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(10, 30)\n",
    "        self.fc2 = nn.Linear(30, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "model = SimpleNN()\n",
    "model.apply(xavier_init)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "for epoch in range(30):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for xb, yb in loader:\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(xb)\n",
    "        loss = criterion(preds, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "    print(f\"Epoch {epoch+1} Loss: {total_loss/len(dataset):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef5ee24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.6828 LR: 0.01000\n",
      "Epoch 2 Loss: 0.6448 LR: 0.01000\n",
      "Epoch 3 Loss: 0.6032 LR: 0.01000\n",
      "Epoch 4 Loss: 0.5496 LR: 0.01000\n",
      "Epoch 5 Loss: 0.4850 LR: 0.01000\n",
      "Epoch 6 Loss: 0.4182 LR: 0.01000\n",
      "Epoch 7 Loss: 0.3591 LR: 0.01000\n",
      "Epoch 8 Loss: 0.3103 LR: 0.01000\n",
      "Epoch 9 Loss: 0.2777 LR: 0.01000\n",
      "Epoch 10 Loss: 0.2478 LR: 0.00100\n",
      "Epoch 11 Loss: 0.2267 LR: 0.00100\n",
      "Epoch 12 Loss: 0.2243 LR: 0.00100\n",
      "Epoch 13 Loss: 0.2219 LR: 0.00100\n",
      "Epoch 14 Loss: 0.2202 LR: 0.00100\n",
      "Epoch 15 Loss: 0.2197 LR: 0.00100\n",
      "Epoch 16 Loss: 0.2170 LR: 0.00100\n",
      "Epoch 17 Loss: 0.2141 LR: 0.00100\n",
      "Epoch 18 Loss: 0.2124 LR: 0.00100\n",
      "Epoch 19 Loss: 0.2109 LR: 0.00100\n",
      "Epoch 20 Loss: 0.2086 LR: 0.00010\n",
      "Epoch 21 Loss: 0.2072 LR: 0.00010\n",
      "Epoch 22 Loss: 0.2070 LR: 0.00010\n",
      "Epoch 23 Loss: 0.2068 LR: 0.00010\n",
      "Epoch 24 Loss: 0.2066 LR: 0.00010\n",
      "Epoch 25 Loss: 0.2064 LR: 0.00010\n",
      "Epoch 26 Loss: 0.2063 LR: 0.00010\n",
      "Epoch 27 Loss: 0.2061 LR: 0.00010\n",
      "Epoch 28 Loss: 0.2059 LR: 0.00010\n",
      "Epoch 29 Loss: 0.2057 LR: 0.00010\n",
      "Epoch 30 Loss: 0.2056 LR: 0.00001\n",
      "Epoch 31 Loss: 0.2054 LR: 0.00001\n",
      "Epoch 32 Loss: 0.2053 LR: 0.00001\n",
      "Epoch 33 Loss: 0.2053 LR: 0.00001\n",
      "Epoch 34 Loss: 0.2053 LR: 0.00001\n",
      "Epoch 35 Loss: 0.2053 LR: 0.00001\n",
      "Epoch 36 Loss: 0.2053 LR: 0.00001\n",
      "Epoch 37 Loss: 0.2052 LR: 0.00001\n",
      "Epoch 38 Loss: 0.2052 LR: 0.00001\n",
      "Epoch 39 Loss: 0.2052 LR: 0.00001\n",
      "Epoch 40 Loss: 0.2052 LR: 0.00000\n"
     ]
    }
   ],
   "source": [
    "#3. Training with Gradient Clipping and Learning Rate Scheduler (StepLR)\n",
    "\n",
    "model = SimpleNN()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "for epoch in range(40):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for xb, yb in loader:\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(xb)\n",
    "        loss = criterion(preds, yb)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch {epoch+1} Loss: {total_loss/len(dataset):.4f} LR: {scheduler.get_last_lr()[0]:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e9543850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.0851\n",
      "Epoch 2 Loss: 0.0825\n",
      "Epoch 3 Loss: 0.0807\n",
      "Epoch 4 Loss: 0.0784\n",
      "Epoch 5 Loss: 0.0759\n",
      "Epoch 6 Loss: 0.0736\n",
      "Epoch 7 Loss: 0.0718\n",
      "Epoch 8 Loss: 0.0706\n",
      "Epoch 9 Loss: 0.0701\n",
      "Epoch 10 Loss: 0.0698\n",
      "Epoch 11 Loss: 0.0695\n",
      "Epoch 12 Loss: 0.0693\n",
      "Epoch 13 Loss: 0.0691\n",
      "Epoch 14 Loss: 0.0690\n",
      "Epoch 15 Loss: 0.0689\n",
      "Epoch 16 Loss: 0.0687\n",
      "Epoch 17 Loss: 0.0685\n",
      "Epoch 18 Loss: 0.0684\n",
      "Epoch 19 Loss: 0.0683\n",
      "Epoch 20 Loss: 0.0683\n",
      "Epoch 21 Loss: 0.0682\n",
      "Epoch 22 Loss: 0.0682\n",
      "Epoch 23 Loss: 0.0680\n",
      "Epoch 24 Loss: 0.0680\n",
      "Epoch 25 Loss: 0.0679\n",
      "Epoch 26 Loss: 0.0679\n",
      "Epoch 27 Loss: 0.0678\n",
      "Epoch 28 Loss: 0.0677\n",
      "Epoch 29 Loss: 0.0677\n",
      "Epoch 30 Loss: 0.0677\n",
      "Epoch 31 Loss: 0.0676\n",
      "Epoch 32 Loss: 0.0675\n",
      "Epoch 33 Loss: 0.0675\n",
      "Epoch 34 Loss: 0.0675\n",
      "Epoch 35 Loss: 0.0675\n",
      "Epoch 36 Loss: 0.0675\n",
      "Epoch 37 Loss: 0.0675\n",
      "Epoch 38 Loss: 0.0674\n",
      "Epoch 39 Loss: 0.0674\n",
      "Epoch 40 Loss: 0.0674\n",
      "Epoch 41 Loss: 0.0674\n",
      "Epoch 42 Loss: 0.0673\n",
      "Epoch 43 Loss: 0.0675\n",
      "Epoch 44 Loss: 0.0674\n",
      "Epoch 45 Loss: 0.0672\n",
      "Epoch 46 Loss: 0.0673\n",
      "Epoch 47 Loss: 0.0672\n",
      "Epoch 48 Loss: 0.0673\n",
      "Epoch 49 Loss: 0.0672\n",
      "Epoch 50 Loss: 0.0672\n"
     ]
    }
   ],
   "source": [
    "#4. Simple Autoencoder Training on Random Data\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(20, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 3)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 20),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "X_ae = torch.rand(500, 20)\n",
    "dataset_ae = TensorDataset(X_ae, X_ae)  # Autoencoder input=target\n",
    "loader_ae = DataLoader(dataset_ae, batch_size=32, shuffle=True)\n",
    "\n",
    "model_ae = Autoencoder()\n",
    "criterion_ae = nn.MSELoss()\n",
    "optimizer_ae = optim.Adam(model_ae.parameters(), lr=0.005)\n",
    "\n",
    "for epoch in range(50):\n",
    "    model_ae.train()\n",
    "    total_loss = 0\n",
    "    for xb, yb in loader_ae:\n",
    "        optimizer_ae.zero_grad()\n",
    "        out = model_ae(xb)\n",
    "        loss = criterion_ae(out, yb)\n",
    "        loss.backward()\n",
    "        optimizer_ae.step()\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "    print(f\"Epoch {epoch+1} Loss: {total_loss/len(dataset_ae):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08147f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 1.0081\n",
      "Epoch 2 Loss: 0.9794\n",
      "Epoch 3 Loss: 0.9521\n",
      "Epoch 4 Loss: 0.9263\n",
      "Epoch 5 Loss: 0.9022\n",
      "Epoch 6 Loss: 0.8798\n",
      "Epoch 7 Loss: 0.8591\n",
      "Epoch 8 Loss: 0.8398\n",
      "Epoch 9 Loss: 0.8218\n",
      "Epoch 10 Loss: 0.8050\n",
      "Epoch 11 Loss: 0.7891\n",
      "Epoch 12 Loss: 0.7739\n",
      "Epoch 13 Loss: 0.7594\n",
      "Epoch 14 Loss: 0.7455\n",
      "Epoch 15 Loss: 0.7322\n",
      "Epoch 16 Loss: 0.7196\n",
      "Epoch 17 Loss: 0.7076\n",
      "Epoch 18 Loss: 0.6962\n",
      "Epoch 19 Loss: 0.6856\n",
      "Epoch 20 Loss: 0.6756\n",
      "Epoch 21 Loss: 0.6664\n",
      "Epoch 22 Loss: 0.6578\n",
      "Epoch 23 Loss: 0.6500\n",
      "Epoch 24 Loss: 0.6429\n",
      "Epoch 25 Loss: 0.6364\n",
      "Epoch 26 Loss: 0.6304\n",
      "Epoch 27 Loss: 0.6250\n",
      "Epoch 28 Loss: 0.6199\n",
      "Epoch 29 Loss: 0.6153\n",
      "Epoch 30 Loss: 0.6108\n"
     ]
    }
   ],
   "source": [
    "#5. RNN Training (Backprop Through Time)\n",
    "seq_len = 5\n",
    "input_size = 3\n",
    "hidden_size = 4\n",
    "batch_size = 2\n",
    "\n",
    "rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(rnn.parameters(), lr=0.01)\n",
    "\n",
    "# Random data: batch_size x seq_len x input_size\n",
    "X_rnn = torch.randn(batch_size, seq_len, input_size)\n",
    "y_rnn = torch.randn(batch_size, seq_len, hidden_size)\n",
    "\n",
    "for epoch in range(30):\n",
    "    optimizer.zero_grad()\n",
    "    out, hn = rnn(X_rnn)\n",
    "    loss = criterion(out, y_rnn)\n",
    "    loss.backward()  # PyTorch does BPTT automatically\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch+1} Loss: {loss.item():.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
